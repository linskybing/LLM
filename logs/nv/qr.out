
CondaError: Run 'conda init' before 'conda deactivate'

-----------------------
loading miniconda3 with conda 24.5.0 and python 3.9
docs : https://hackmd.io/@kmo/twcc_hpc_conda
-----------------------

+--------------------------------------------------+
| Nvidia hpc sdk v24.11 with cuda v12.6 is loaded. |
+--------------------------------------------------+
[2025-10-28 20:47:41,939] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-10-28 20:47:41,948] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-10-28 20:47:41,955] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-10-28 20:47:41,964] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-10-28 20:47:41,966] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-10-28 20:47:41,969] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-10-28 20:47:41,970] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-10-28 20:47:41,971] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-10-28 20:48:23,211] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[2025-10-28 20:48:23,211] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[2025-10-28 20:48:23,211] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[2025-10-28 20:48:23,211] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[2025-10-28 20:48:23,211] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[2025-10-28 20:48:23,211] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[2025-10-28 20:48:23,211] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[2025-10-28 20:48:23,211] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[nltk_data] Downloading package words to /home/u8644434/nltk_data...
[nltk_data] Downloading package words to /home/u8644434/nltk_data...
[nltk_data]   Package words is already up-to-date!
[nltk_data] Downloading package words to /home/u8644434/nltk_data...
[nltk_data] Downloading package words to /home/u8644434/nltk_data...
[nltk_data]   Package words is already up-to-date!
[nltk_data] Downloading package words to /home/u8644434/nltk_data...
[nltk_data]   Package words is already up-to-date!
[nltk_data]   Package words is already up-to-date!
[nltk_data] Downloading package words to /home/u8644434/nltk_data...
[nltk_data]   Package words is already up-to-date!
[nltk_data] Downloading package words to /home/u8644434/nltk_data...
[nltk_data]   Package words is already up-to-date!
[nltk_data]   Package words is already up-to-date!
[nltk_data] Downloading package words to /home/u8644434/nltk_data...
[nltk_data]   Package words is already up-to-date!
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:30<00:30, 30.56s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:31<00:31, 31.16s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:30<00:30, 30.73s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:30<00:30, 30.73s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:31<00:31, 31.27s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:30<00:30, 30.82s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:30<00:30, 30.74s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:30<00:30, 30.84s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:41<00:00, 18.87s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:41<00:00, 20.63s/it]
The module name  (originally ) is not a valid Python identifier. Please rename the original module to avoid import issues.
[2025-10-28 20:49:18,439] [INFO] [logging.py:107:log_dist] [Rank -1] DeepSpeed info: version=0.17.4, git-hash=unknown, git-branch=unknown
[2025-10-28 20:49:18,440] [INFO] [comm.py:821:init_distributed] cdb=None
[2025-10-28 20:49:18,441] [INFO] [config.py:684:__init__] Config mesh_device None world_size = 8
Loading checkpoint shards: 100%|██████████| 2/2 [00:41<00:00, 18.88s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:41<00:00, 20.66s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:41<00:00, 18.92s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:41<00:00, 20.71s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:41<00:00, 18.89s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:41<00:00, 19.06s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:41<00:00, 18.89s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:41<00:00, 20.66s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:41<00:00, 20.87s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:41<00:00, 20.67s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:41<00:00, 18.93s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:41<00:00, 19.11s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:41<00:00, 20.72s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:41<00:00, 20.93s/it]
The module name  (originally ) is not a valid Python identifier. Please rename the original module to avoid import issues.
The module name  (originally ) is not a valid Python identifier. Please rename the original module to avoid import issues.
The module name  (originally ) is not a valid Python identifier. Please rename the original module to avoid import issues.
The module name  (originally ) is not a valid Python identifier. Please rename the original module to avoid import issues.
The module name  (originally ) is not a valid Python identifier. Please rename the original module to avoid import issues.
The module name  (originally ) is not a valid Python identifier. Please rename the original module to avoid import issues.
The module name  (originally ) is not a valid Python identifier. Please rename the original module to avoid import issues.
[2025-10-28 20:49:18,502] [INFO] [logging.py:107:log_dist] [Rank -1] DeepSpeed info: version=0.17.4, git-hash=unknown, git-branch=unknown
[2025-10-28 20:49:18,503] [INFO] [comm.py:821:init_distributed] cdb=None
[2025-10-28 20:49:18,503] [INFO] [config.py:684:__init__] Config mesh_device None world_size = 8
[2025-10-28 20:49:18,503] [INFO] [logging.py:107:log_dist] [Rank -1] DeepSpeed info: version=0.17.4, git-hash=unknown, git-branch=unknown
[2025-10-28 20:49:18,503] [INFO] [logging.py:107:log_dist] [Rank -1] DeepSpeed info: version=0.17.4, git-hash=unknown, git-branch=unknown
[2025-10-28 20:49:18,503] [INFO] [comm.py:821:init_distributed] cdb=None
[2025-10-28 20:49:18,503] [INFO] [comm.py:821:init_distributed] cdb=None
[2025-10-28 20:49:18,504] [INFO] [logging.py:107:log_dist] [Rank -1] DeepSpeed info: version=0.17.4, git-hash=unknown, git-branch=unknown
[2025-10-28 20:49:18,504] [INFO] [comm.py:821:init_distributed] cdb=None
[2025-10-28 20:49:18,504] [INFO] [config.py:684:__init__] Config mesh_device None world_size = 8
[2025-10-28 20:49:18,504] [INFO] [config.py:684:__init__] Config mesh_device None world_size = 8
[2025-10-28 20:49:18,504] [INFO] [logging.py:107:log_dist] [Rank -1] DeepSpeed info: version=0.17.4, git-hash=unknown, git-branch=unknown
[2025-10-28 20:49:18,504] [INFO] [comm.py:821:init_distributed] cdb=None
[2025-10-28 20:49:18,504] [INFO] [config.py:684:__init__] Config mesh_device None world_size = 8
[2025-10-28 20:49:18,504] [INFO] [logging.py:107:log_dist] [Rank -1] DeepSpeed info: version=0.17.4, git-hash=unknown, git-branch=unknown
[2025-10-28 20:49:18,505] [INFO] [comm.py:821:init_distributed] cdb=None
[2025-10-28 20:49:18,505] [INFO] [logging.py:107:log_dist] [Rank -1] DeepSpeed info: version=0.17.4, git-hash=unknown, git-branch=unknown
[2025-10-28 20:49:18,505] [INFO] [comm.py:821:init_distributed] cdb=None
[2025-10-28 20:49:18,505] [INFO] [config.py:684:__init__] Config mesh_device None world_size = 8
[2025-10-28 20:49:18,505] [INFO] [config.py:684:__init__] Config mesh_device None world_size = 8
[2025-10-28 20:49:18,505] [INFO] [config.py:684:__init__] Config mesh_device None world_size = 8
[2025-10-28 20:49:18,519] [INFO] [engine.py:1339:_configure_distributed_model] ********** distributed groups summary **********
	 self.dp_world_size=8
	 self.mp_world_size=1
	 self.seq_dp_world_size=8
	 self.sequence_parallel_size=1
***********************************************
[2025-10-28 20:49:20,201] [INFO] [logging.py:107:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2025-10-28 20:49:20,201] [INFO] [logging.py:107:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[2025-10-28 20:49:20,202] [INFO] [logging.py:107:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer
[2025-10-28 20:49:20,210] [INFO] [logging.py:107:log_dist] [Rank 0] DeepSpeed Basic Optimizer = Adam8bit
[2025-10-28 20:49:20,211] [INFO] [logging.py:107:log_dist] [Rank 0] Creating BF16 optimizer
[2025-10-28 20:49:20,384] [INFO] [utils.py:781:see_memory_usage] begin bf16_optimizer
[2025-10-28 20:49:20,385] [INFO] [utils.py:782:see_memory_usage] MA 3.61 GB         Max_MA 3.86 GB         CA 4.34 GB         Max_CA 4 GB 
[2025-10-28 20:49:20,385] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 40.02 GB, percent = 5.3%
[2025-10-28 20:49:20,548] [INFO] [utils.py:781:see_memory_usage] before initializing group 0
[2025-10-28 20:49:20,549] [INFO] [utils.py:782:see_memory_usage] MA 3.61 GB         Max_MA 3.61 GB         CA 4.34 GB         Max_CA 4 GB 
[2025-10-28 20:49:20,549] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 40.14 GB, percent = 5.3%
[2025-10-28 20:49:20,736] [INFO] [utils.py:781:see_memory_usage] after initializing group 0
[2025-10-28 20:49:20,737] [INFO] [utils.py:782:see_memory_usage] MA 4.71 GB         Max_MA 4.71 GB         CA 5.81 GB         Max_CA 6 GB 
[2025-10-28 20:49:20,737] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 40.25 GB, percent = 5.3%
[2025-10-28 20:49:20,916] [INFO] [utils.py:781:see_memory_usage] end bf16_ optimizer
[2025-10-28 20:49:20,916] [INFO] [utils.py:782:see_memory_usage] MA 4.71 GB         Max_MA 4.71 GB         CA 5.81 GB         Max_CA 6 GB 
[2025-10-28 20:49:20,916] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 40.43 GB, percent = 5.4%
[2025-10-28 20:49:20,917] [INFO] [logging.py:107:log_dist] [Rank 0] DeepSpeed Final Optimizer = BF16_Optimizer
[2025-10-28 20:49:20,917] [INFO] [logging.py:107:log_dist] [Rank 0] DeepSpeed using configured LR scheduler = None
[2025-10-28 20:49:20,917] [INFO] [logging.py:107:log_dist] [Rank 0] DeepSpeed LR Scheduler = None
[2025-10-28 20:49:20,917] [INFO] [logging.py:107:log_dist] [Rank 0] step=0, skipped=0, lr=[2e-05], mom=[(0.9, 0.999)]
[2025-10-28 20:49:20,917] [INFO] [logging.py:107:log_dist] [Rank 0] [TorchCheckpointEngine] Initialized with serialization = True
[2025-10-28 20:49:20,918] [INFO] [config.py:954:print] DeepSpeedEngine configuration:
[2025-10-28 20:49:20,918] [INFO] [config.py:958:print]   activation_checkpointing_config  {
    "partition_activations": true, 
    "contiguous_memory_optimization": true, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": true, 
    "profile": false
}
[2025-10-28 20:49:20,918] [INFO] [config.py:958:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'intra_op_parallelism': 1, 'single_submit': False, 'overlap_events': True, 'use_gds': False}
[2025-10-28 20:49:20,918] [INFO] [config.py:958:print]   amp_enabled .................. False
[2025-10-28 20:49:20,918] [INFO] [config.py:958:print]   amp_params ................... False
[2025-10-28 20:49:20,918] [INFO] [config.py:958:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2025-10-28 20:49:20,918] [INFO] [config.py:958:print]   bfloat16_config .............. enabled=True immediate_grad_update=False check_grad_overflow=False
[2025-10-28 20:49:20,918] [INFO] [config.py:958:print]   checkpoint_config ............ {'tag_validation': 'WARN', 'checkpoint_serialization': True, 'writer': None}
[2025-10-28 20:49:20,918] [INFO] [config.py:958:print]   checkpoint_parallel_write_pipeline  False
[2025-10-28 20:49:20,918] [INFO] [config.py:958:print]   checkpoint_tag_validation_enabled  True
[2025-10-28 20:49:20,918] [INFO] [config.py:958:print]   checkpoint_tag_validation_fail  False
[2025-10-28 20:49:20,918] [INFO] [config.py:958:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x151e89bcf170>
[2025-10-28 20:49:20,918] [INFO] [config.py:958:print]   communication_data_type ...... None
[2025-10-28 20:49:20,918] [INFO] [config.py:958:print]   compile_config ............... deepcompile=False free_activation=False offload_activation=False offload_opt_states=False double_buffer=True symmetric_memory=False debug_log=False offload_parameters=False sync_before_reduce=False sync_after_reduce=False sync_before_allgather=False sync_after_allgather=False keep_int_input_tensors=True keep_all_input_tensors=False
[2025-10-28 20:49:20,918] [INFO] [config.py:958:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2025-10-28 20:49:20,918] [INFO] [config.py:958:print]   curriculum_enabled_legacy .... False
[2025-10-28 20:49:20,918] [INFO] [config.py:958:print]   curriculum_params_legacy ..... False
[2025-10-28 20:49:20,919] [INFO] [config.py:958:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'pin_memory': False, 'curriculum_learning': {'enabled': False}, 'dynamic_batching': {'enabled': False, 'lr_scaling_method': 'linear', 'min_batch_size': 1, 'max_batch_size': None, 'sequence_picking_order': 'dataloader', 'verbose': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2025-10-28 20:49:20,919] [INFO] [config.py:958:print]   data_efficiency_enabled ...... False
[2025-10-28 20:49:20,919] [INFO] [config.py:958:print]   dataloader_drop_last ......... False
[2025-10-28 20:49:20,919] [INFO] [config.py:958:print]   disable_allgather ............ False
[2025-10-28 20:49:20,919] [INFO] [config.py:958:print]   dump_state ................... False
[2025-10-28 20:49:20,919] [INFO] [config.py:958:print]   eigenvalue_enabled ........... False
[2025-10-28 20:49:20,919] [INFO] [config.py:958:print]   eigenvalue_gas_boundary_resolution  1
[2025-10-28 20:49:20,919] [INFO] [config.py:958:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2025-10-28 20:49:20,919] [INFO] [config.py:958:print]   eigenvalue_layer_num ......... 0
[2025-10-28 20:49:20,919] [INFO] [config.py:958:print]   eigenvalue_max_iter .......... 100
[2025-10-28 20:49:20,919] [INFO] [config.py:958:print]   eigenvalue_stability ......... 1e-06
[2025-10-28 20:49:20,919] [INFO] [config.py:958:print]   eigenvalue_tol ............... 0.01
[2025-10-28 20:49:20,919] [INFO] [config.py:958:print]   eigenvalue_verbose ........... False
[2025-10-28 20:49:20,919] [INFO] [config.py:958:print]   elasticity_enabled ........... False
[2025-10-28 20:49:20,919] [INFO] [config.py:958:print]   float16_config ............... enabled=False auto_cast=False loss_scale=0.0 initial_scale_power=16 loss_scale_window=1000 hysteresis=2 consecutive_hysteresis=False min_loss_scale=1 fp16_master_weights_and_grads=False
[2025-10-28 20:49:20,919] [INFO] [config.py:958:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2025-10-28 20:49:20,919] [INFO] [config.py:958:print]   global_rank .................. 0
[2025-10-28 20:49:20,919] [INFO] [config.py:958:print]   grad_accum_dtype ............. None
[2025-10-28 20:49:20,919] [INFO] [config.py:958:print]   gradient_accumulation_steps .. 1
[2025-10-28 20:49:20,919] [INFO] [config.py:958:print]   gradient_clipping ............ 1
[2025-10-28 20:49:20,919] [INFO] [config.py:958:print]   gradient_predivide_factor .... 1.0
[2025-10-28 20:49:20,919] [INFO] [config.py:958:print]   graph_harvesting ............. False
[2025-10-28 20:49:20,919] [INFO] [config.py:958:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2025-10-28 20:49:20,919] [INFO] [config.py:958:print]   load_universal_checkpoint .... False
[2025-10-28 20:49:20,919] [INFO] [config.py:958:print]   memory_breakdown ............. False
[2025-10-28 20:49:20,919] [INFO] [config.py:958:print]   mics_hierarchial_params_gather  False
[2025-10-28 20:49:20,919] [INFO] [config.py:958:print]   mics_shard_size .............. -1
[2025-10-28 20:49:20,919] [INFO] [config.py:958:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') comet=CometConfig(enabled=False, samples_log_interval=100, project=None, workspace=None, api_key=None, experiment_name=None, experiment_key=None, online=None, mode=None) wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName')
[2025-10-28 20:49:20,919] [INFO] [config.py:958:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2025-10-28 20:49:20,919] [INFO] [config.py:958:print]   optimizer_legacy_fusion ...... False
[2025-10-28 20:49:20,919] [INFO] [config.py:958:print]   optimizer_name ............... zerooneadam
[2025-10-28 20:49:20,919] [INFO] [config.py:958:print]   optimizer_params ............. {'lr': 0.001, 'weight_decay': 0.01, 'bias_correction': False, 'var_freeze_step': 1000, 'var_update_scaler': 16, 'local_step_scaler': 1000, 'local_step_clipper': 16, 'cuda_aware': False, 'comm_backend_name': 'nccl'}
[2025-10-28 20:49:20,919] [INFO] [config.py:958:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}
[2025-10-28 20:49:20,919] [INFO] [config.py:958:print]   pld_enabled .................. False
[2025-10-28 20:49:20,919] [INFO] [config.py:958:print]   pld_params ................... False
[2025-10-28 20:49:20,919] [INFO] [config.py:958:print]   prescale_gradients ........... False
[2025-10-28 20:49:20,919] [INFO] [config.py:958:print]   scheduler_name ............... None
[2025-10-28 20:49:20,919] [INFO] [config.py:958:print]   scheduler_params ............. None
[2025-10-28 20:49:20,919] [INFO] [config.py:958:print]   seq_parallel_communication_data_type  torch.float32
[2025-10-28 20:49:20,919] [INFO] [config.py:958:print]   sparse_attention ............. None
[2025-10-28 20:49:20,919] [INFO] [config.py:958:print]   sparse_gradients_enabled ..... False
[2025-10-28 20:49:20,919] [INFO] [config.py:958:print]   steps_per_print .............. 1
[2025-10-28 20:49:20,919] [INFO] [config.py:958:print]   tensor_parallel_config ....... dtype=torch.float16 autotp_size=0 tp_overlap_comm=False tensor_parallel=TPConfig(tp_size=1, tp_grain_size=1, mpu=None, tp_group=None) injection_policy_tuple=None keep_module_on_host=False replace_with_kernel_inject=False
[2025-10-28 20:49:20,919] [INFO] [config.py:958:print]   timers_config ................ enabled=True synchronized=True
[2025-10-28 20:49:20,919] [INFO] [config.py:958:print]   torch_autocast_dtype ......... None
[2025-10-28 20:49:20,919] [INFO] [config.py:958:print]   torch_autocast_enabled ....... False
[2025-10-28 20:49:20,919] [INFO] [config.py:958:print]   torch_autocast_lower_precision_safe_modules  None
[2025-10-28 20:49:20,920] [INFO] [config.py:958:print]   train_batch_size ............. 8
[2025-10-28 20:49:20,920] [INFO] [config.py:958:print]   train_micro_batch_size_per_gpu  1
[2025-10-28 20:49:20,920] [INFO] [config.py:958:print]   use_data_before_expert_parallel_  False
[2025-10-28 20:49:20,920] [INFO] [config.py:958:print]   use_node_local_storage ....... False
[2025-10-28 20:49:20,920] [INFO] [config.py:958:print]   wall_clock_breakdown ......... False
[2025-10-28 20:49:20,920] [INFO] [config.py:958:print]   weight_quantization_config ... None
[2025-10-28 20:49:20,920] [INFO] [config.py:958:print]   world_size ................... 8
[2025-10-28 20:49:20,920] [INFO] [config.py:958:print]   zero_allow_untested_optimizer  False
[2025-10-28 20:49:20,920] [INFO] [config.py:958:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=500000000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50000000 param_persistence_threshold=100000 model_persistence_threshold=9223372036854775807 max_live_parameters=1000000000 max_reuse_distance=1000000000 gather_16bit_weights_on_model_save=False module_granularity_threshold=0 use_all_reduce_for_fetch_params=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False zeropp_loco_param=None mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True log_trace_cache_warnings=False
[2025-10-28 20:49:20,920] [INFO] [config.py:958:print]   zero_enabled ................. False
[2025-10-28 20:49:20,920] [INFO] [config.py:958:print]   zero_force_ds_cpu_optimizer .. True
[2025-10-28 20:49:20,920] [INFO] [config.py:958:print]   zero_optimization_stage ...... 0
[2025-10-28 20:49:20,920] [INFO] [config.py:944:print_user_config]   json = {
    "train_batch_size": 8, 
    "train_micro_batch_size_per_gpu": 1, 
    "steps_per_print": 1, 
    "gradient_accumulation_steps": 1, 
    "optimizer": {
        "type": "ZeroOneAdam", 
        "params": {
            "lr": 0.001, 
            "weight_decay": 0.01, 
            "bias_correction": false, 
            "var_freeze_step": 1000, 
            "var_update_scaler": 16, 
            "local_step_scaler": 1000, 
            "local_step_clipper": 16, 
            "cuda_aware": false, 
            "comm_backend_name": "nccl"
        }
    }, 
    "gradient_clipping": 1, 
    "bf16": {
        "enabled": true
    }, 
    "quantize_training": {
        "enabled": true, 
        "quantize_verbose": true, 
        "quantizer_kernel": true, 
        "quantize_type": "symmetric", 
        "quantize_bits": {
            "start_bits": 16, 
            "target_bits": 8
        }, 
        "quantize_schedule": {
            "quantize_period": 100, 
            "schedule_offset": 0
        }, 
        "quantize_groups": 8
    }, 
    "activation_checkpointing": {
        "partition_activations": true, 
        "contiguous_memory_optimization": true, 
        "cpu_checkpointing": false, 
        "number_checkpoints": null, 
        "synchronize_checkpoint_boundary": true, 
        "profile": false
    }, 
    "gradient_checkpointing": {
        "enable": true
    }, 
    "flops_profiler": {
        "enabled": false, 
        "profile_step": 1, 
        "module_depth": -1, 
        "top_modules": 1, 
        "detailed": true, 
        "output_file": null
    }
}
[2025-10-28 20:49:22,996] [INFO] [logging.py:107:log_dist] [Rank 0] step=1, skipped=0, lr=[2e-05], mom=[(0.9, 0.999)]
[Step 1/100] Loss: 5.4901 | Global Tokens/s: 1347.72 | GPU Mem (GB): 5.28 | Peak Mem: 5.73
[2025-10-28 20:49:23,752] [INFO] [logging.py:107:log_dist] [Rank 0] step=2, skipped=0, lr=[2e-05], mom=[(0.9, 0.999)]
[Step 2/100] Loss: 5.2420 | Global Tokens/s: 5871.81 | GPU Mem (GB): 5.28 | Peak Mem: 5.79
[2025-10-28 20:49:24,232] [INFO] [logging.py:107:log_dist] [Rank 0] step=3, skipped=0, lr=[2e-05], mom=[(0.9, 0.999)]
[2025-10-28 20:49:24,237] [INFO] [timer.py:264:stop] epoch=0/micro_step=3/global_step=3, RunningAvgSamplesPerSec=16.79524569625493, CurrSamplesPerSec=16.795210436294205, MemAllocated=5.3GB, MaxMemAllocated=5.79GB
[Step 3/100] Loss: 5.2516 | Global Tokens/s: 5870.84 | GPU Mem (GB): 5.28 | Peak Mem: 5.79
[2025-10-28 20:49:24,712] [INFO] [logging.py:107:log_dist] [Rank 0] step=4, skipped=0, lr=[2e-05], mom=[(0.9, 0.999)]
[2025-10-28 20:49:24,717] [INFO] [timer.py:264:stop] epoch=0/micro_step=4/global_step=4, RunningAvgSamplesPerSec=16.777262137470878, CurrSamplesPerSec=16.759281940126307, MemAllocated=5.3GB, MaxMemAllocated=5.79GB
[Step 4/100] Loss: 4.9881 | Global Tokens/s: 5858.25 | GPU Mem (GB): 5.28 | Peak Mem: 5.79
[2025-10-28 20:49:25,190] [INFO] [logging.py:107:log_dist] [Rank 0] step=5, skipped=0, lr=[2e-05], mom=[(0.9, 0.999)]
[2025-10-28 20:49:25,196] [INFO] [timer.py:264:stop] epoch=0/micro_step=5/global_step=5, RunningAvgSamplesPerSec=16.796111625578774, CurrSamplesPerSec=16.833902531326945, MemAllocated=5.3GB, MaxMemAllocated=5.79GB
[Step 5/100] Loss: 5.1142 | Global Tokens/s: 5884.44 | GPU Mem (GB): 5.28 | Peak Mem: 5.79
[2025-10-28 20:49:25,670] [INFO] [logging.py:107:log_dist] [Rank 0] step=6, skipped=0, lr=[2e-05], mom=[(0.9, 0.999)]
[2025-10-28 20:49:25,675] [INFO] [timer.py:264:stop] epoch=0/micro_step=6/global_step=6, RunningAvgSamplesPerSec=16.796475258443213, CurrSamplesPerSec=16.79753098180877, MemAllocated=5.3GB, MaxMemAllocated=5.79GB
[Step 6/100] Loss: 5.4106 | Global Tokens/s: 5871.81 | GPU Mem (GB): 5.28 | Peak Mem: 5.79
[2025-10-28 20:49:26,150] [INFO] [logging.py:107:log_dist] [Rank 0] step=7, skipped=0, lr=[2e-05], mom=[(0.9, 0.999)]
[2025-10-28 20:49:26,155] [INFO] [timer.py:264:stop] epoch=0/micro_step=7/global_step=7, RunningAvgSamplesPerSec=16.79207866882978, CurrSamplesPerSec=16.774480130064507, MemAllocated=5.3GB, MaxMemAllocated=5.79GB
[Step 7/100] Loss: 5.1627 | Global Tokens/s: 5863.27 | GPU Mem (GB): 5.28 | Peak Mem: 5.79
[2025-10-28 20:49:26,629] [INFO] [logging.py:107:log_dist] [Rank 0] step=8, skipped=0, lr=[2e-05], mom=[(0.9, 0.999)]
[2025-10-28 20:49:26,635] [INFO] [timer.py:264:stop] epoch=0/micro_step=8/global_step=8, RunningAvgSamplesPerSec=16.791002812559345, CurrSamplesPerSec=16.785590378845367, MemAllocated=5.3GB, MaxMemAllocated=5.79GB
[Step 8/100] Loss: 5.1976 | Global Tokens/s: 5867.35 | GPU Mem (GB): 5.28 | Peak Mem: 5.79
[2025-10-28 20:49:27,107] [INFO] [logging.py:107:log_dist] [Rank 0] step=9, skipped=0, lr=[2e-05], mom=[(0.9, 0.999)]
[2025-10-28 20:49:27,112] [INFO] [timer.py:264:stop] epoch=0/micro_step=9/global_step=9, RunningAvgSamplesPerSec=16.80199894844896, CurrSamplesPerSec=16.868243839094045, MemAllocated=5.3GB, MaxMemAllocated=5.79GB
[Step 9/100] Loss: 4.7918 | Global Tokens/s: 5896.38 | GPU Mem (GB): 5.28 | Peak Mem: 5.79
[2025-10-28 20:49:27,585] [INFO] [logging.py:107:log_dist] [Rank 0] step=10, skipped=0, lr=[2e-05], mom=[(0.9, 0.999)]
[2025-10-28 20:49:27,590] [INFO] [timer.py:264:stop] epoch=0/micro_step=10/global_step=10, RunningAvgSamplesPerSec=16.807602043544474, CurrSamplesPerSec=16.846893113206864, MemAllocated=5.3GB, MaxMemAllocated=5.79GB
[Step 10/100] Loss: 5.0774 | Global Tokens/s: 5888.73 | GPU Mem (GB): 5.28 | Peak Mem: 5.79
[2025-10-28 20:49:28,064] [INFO] [logging.py:107:log_dist] [Rank 0] step=11, skipped=0, lr=[2e-05], mom=[(0.9, 0.999)]
[2025-10-28 20:49:28,070] [INFO] [timer.py:264:stop] epoch=0/micro_step=11/global_step=11, RunningAvgSamplesPerSec=16.805023646072126, CurrSamplesPerSec=16.784389695957994, MemAllocated=5.3GB, MaxMemAllocated=5.79GB
[Step 11/100] Loss: 5.1651 | Global Tokens/s: 5867.14 | GPU Mem (GB): 5.28 | Peak Mem: 5.79
[2025-10-28 20:49:28,544] [INFO] [logging.py:107:log_dist] [Rank 0] step=12, skipped=0, lr=[2e-05], mom=[(0.9, 0.999)]
[2025-10-28 20:49:28,549] [INFO] [timer.py:264:stop] epoch=0/micro_step=12/global_step=12, RunningAvgSamplesPerSec=16.804577212617584, CurrSamplesPerSec=16.800525096366595, MemAllocated=5.3GB, MaxMemAllocated=5.79GB
[Step 12/100] Loss: 4.9932 | Global Tokens/s: 5872.73 | GPU Mem (GB): 5.28 | Peak Mem: 5.79
[2025-10-28 20:49:29,023] [INFO] [logging.py:107:log_dist] [Rank 0] step=13, skipped=0, lr=[2e-05], mom=[(0.9, 0.999)]
[2025-10-28 20:49:29,028] [INFO] [timer.py:264:stop] epoch=0/micro_step=13/global_step=13, RunningAvgSamplesPerSec=16.804396347255487, CurrSamplesPerSec=16.802552616944762, MemAllocated=5.3GB, MaxMemAllocated=5.79GB
[Step 13/100] Loss: 5.1528 | Global Tokens/s: 5873.26 | GPU Mem (GB): 5.28 | Peak Mem: 5.79
[2025-10-28 20:49:29,503] [INFO] [logging.py:107:log_dist] [Rank 0] step=14, skipped=0, lr=[2e-05], mom=[(0.9, 0.999)]
[2025-10-28 20:49:29,508] [INFO] [timer.py:264:stop] epoch=0/micro_step=14/global_step=14, RunningAvgSamplesPerSec=16.802910450563985, CurrSamplesPerSec=16.786547689668776, MemAllocated=5.3GB, MaxMemAllocated=5.79GB
[Step 14/100] Loss: 4.8808 | Global Tokens/s: 5867.95 | GPU Mem (GB): 5.28 | Peak Mem: 5.79
[2025-10-28 20:49:29,982] [INFO] [logging.py:107:log_dist] [Rank 0] step=15, skipped=0, lr=[2e-05], mom=[(0.9, 0.999)]
[2025-10-28 20:49:29,987] [INFO] [timer.py:264:stop] epoch=0/micro_step=15/global_step=15, RunningAvgSamplesPerSec=16.80196853079365, CurrSamplesPerSec=16.79063848422403, MemAllocated=5.3GB, MaxMemAllocated=5.79GB
[Step 15/100] Loss: 5.0514 | Global Tokens/s: 5869.10 | GPU Mem (GB): 5.28 | Peak Mem: 5.79
[2025-10-28 20:49:30,461] [INFO] [logging.py:107:log_dist] [Rank 0] step=16, skipped=0, lr=[2e-05], mom=[(0.9, 0.999)]
[2025-10-28 20:49:30,466] [INFO] [timer.py:264:stop] epoch=0/micro_step=16/global_step=16, RunningAvgSamplesPerSec=16.803285697642547, CurrSamplesPerSec=16.820392312932544, MemAllocated=5.3GB, MaxMemAllocated=5.79GB
[Step 16/100] Loss: 5.1094 | Global Tokens/s: 5879.52 | GPU Mem (GB): 5.28 | Peak Mem: 5.79
[2025-10-28 20:49:30,940] [INFO] [logging.py:107:log_dist] [Rank 0] step=17, skipped=0, lr=[2e-05], mom=[(0.9, 0.999)]
[2025-10-28 20:49:30,946] [INFO] [timer.py:264:stop] epoch=0/micro_step=17/global_step=17, RunningAvgSamplesPerSec=16.802228357206815, CurrSamplesPerSec=16.787404323494457, MemAllocated=5.3GB, MaxMemAllocated=5.79GB
[Step 17/100] Loss: 4.8191 | Global Tokens/s: 5867.98 | GPU Mem (GB): 5.28 | Peak Mem: 5.79
[2025-10-28 20:49:31,419] [INFO] [logging.py:107:log_dist] [Rank 0] step=18, skipped=0, lr=[2e-05], mom=[(0.9, 0.999)]
[2025-10-28 20:49:31,425] [INFO] [timer.py:264:stop] epoch=0/micro_step=18/global_step=18, RunningAvgSamplesPerSec=16.802466431507025, CurrSamplesPerSec=16.80600305048868, MemAllocated=5.3GB, MaxMemAllocated=5.79GB
[Step 18/100] Loss: 4.9826 | Global Tokens/s: 5874.52 | GPU Mem (GB): 5.28 | Peak Mem: 5.79
[2025-10-28 20:49:31,899] [INFO] [logging.py:107:log_dist] [Rank 0] step=19, skipped=0, lr=[2e-05], mom=[(0.9, 0.999)]
[2025-10-28 20:49:31,904] [INFO] [timer.py:264:stop] epoch=0/micro_step=19/global_step=19, RunningAvgSamplesPerSec=16.802760643968416, CurrSamplesPerSec=16.807434133696546, MemAllocated=5.3GB, MaxMemAllocated=5.79GB
[Step 19/100] Loss: 5.1177 | Global Tokens/s: 5874.83 | GPU Mem (GB): 5.28 | Peak Mem: 5.79
[2025-10-28 20:49:32,378] [INFO] [logging.py:107:log_dist] [Rank 0] step=20, skipped=0, lr=[2e-05], mom=[(0.9, 0.999)]
[2025-10-28 20:49:32,383] [INFO] [timer.py:264:stop] epoch=0/micro_step=20/global_step=20, RunningAvgSamplesPerSec=16.802305576070758, CurrSamplesPerSec=16.794537934256237, MemAllocated=5.3GB, MaxMemAllocated=5.79GB
[Step 20/100] Loss: 4.9570 | Global Tokens/s: 5870.51 | GPU Mem (GB): 5.28 | Peak Mem: 5.79
[2025-10-28 20:49:32,858] [INFO] [logging.py:107:log_dist] [Rank 0] step=21, skipped=0, lr=[2e-05], mom=[(0.9, 0.999)]
[2025-10-28 20:49:32,863] [INFO] [timer.py:264:stop] epoch=0/micro_step=21/global_step=21, RunningAvgSamplesPerSec=16.800784405639774, CurrSamplesPerSec=16.773415191888205, MemAllocated=5.3GB, MaxMemAllocated=5.79GB
[Step 21/100] Loss: 5.3180 | Global Tokens/s: 5862.71 | GPU Mem (GB): 5.28 | Peak Mem: 5.79
[2025-10-28 20:49:33,337] [INFO] [logging.py:107:log_dist] [Rank 0] step=22, skipped=0, lr=[2e-05], mom=[(0.9, 0.999)]
[2025-10-28 20:49:33,342] [INFO] [timer.py:264:stop] epoch=0/micro_step=22/global_step=22, RunningAvgSamplesPerSec=16.801779361337307, CurrSamplesPerSec=16.82067056825129, MemAllocated=5.3GB, MaxMemAllocated=5.79GB
[Step 22/100] Loss: 5.0971 | Global Tokens/s: 5879.62 | GPU Mem (GB): 5.28 | Peak Mem: 5.79
[2025-10-28 20:49:33,818] [INFO] [logging.py:107:log_dist] [Rank 0] step=23, skipped=0, lr=[2e-05], mom=[(0.9, 0.999)]
[2025-10-28 20:49:33,823] [INFO] [timer.py:264:stop] epoch=0/micro_step=23/global_step=23, RunningAvgSamplesPerSec=16.79867831138545, CurrSamplesPerSec=16.73686180018017, MemAllocated=5.3GB, MaxMemAllocated=5.79GB
[Step 23/100] Loss: 5.2197 | Global Tokens/s: 5850.35 | GPU Mem (GB): 5.28 | Peak Mem: 5.79
[2025-10-28 20:49:34,296] [INFO] [logging.py:107:log_dist] [Rank 0] step=24, skipped=0, lr=[2e-05], mom=[(0.9, 0.999)]
[2025-10-28 20:49:34,301] [INFO] [timer.py:264:stop] epoch=0/micro_step=24/global_step=24, RunningAvgSamplesPerSec=16.800977928556684, CurrSamplesPerSec=16.84938025869701, MemAllocated=5.3GB, MaxMemAllocated=5.79GB
[Step 24/100] Loss: 5.2071 | Global Tokens/s: 5889.70 | GPU Mem (GB): 5.28 | Peak Mem: 5.79
[2025-10-28 20:49:34,774] [INFO] [logging.py:107:log_dist] [Rank 0] step=25, skipped=0, lr=[2e-05], mom=[(0.9, 0.999)]
[2025-10-28 20:49:34,779] [INFO] [timer.py:264:stop] epoch=0/micro_step=25/global_step=25, RunningAvgSamplesPerSec=16.802567421507007, CurrSamplesPerSec=16.837577078020416, MemAllocated=5.3GB, MaxMemAllocated=5.79GB
[Step 25/100] Loss: 5.3130 | Global Tokens/s: 5885.27 | GPU Mem (GB): 5.28 | Peak Mem: 5.79
[2025-10-28 20:49:35,253] [INFO] [logging.py:107:log_dist] [Rank 0] step=26, skipped=0, lr=[2e-05], mom=[(0.9, 0.999)]
[2025-10-28 20:49:35,258] [INFO] [timer.py:264:stop] epoch=0/micro_step=26/global_step=26, RunningAvgSamplesPerSec=16.803087854395145, CurrSamplesPerSec=16.81503137194157, MemAllocated=5.3GB, MaxMemAllocated=5.79GB
[Step 26/100] Loss: 5.0286 | Global Tokens/s: 5877.76 | GPU Mem (GB): 5.28 | Peak Mem: 5.79
[2025-10-28 20:49:35,733] [INFO] [logging.py:107:log_dist] [Rank 0] step=27, skipped=0, lr=[2e-05], mom=[(0.9, 0.999)]
[2025-10-28 20:49:35,738] [INFO] [timer.py:264:stop] epoch=0/micro_step=27/global_step=27, RunningAvgSamplesPerSec=16.801391185749353, CurrSamplesPerSec=16.760738565650694, MemAllocated=5.3GB, MaxMemAllocated=5.79GB
[Step 27/100] Loss: 5.0327 | Global Tokens/s: 5858.78 | GPU Mem (GB): 5.28 | Peak Mem: 5.79
[2025-10-28 20:49:36,212] [INFO] [logging.py:107:log_dist] [Rank 0] step=28, skipped=0, lr=[2e-05], mom=[(0.9, 0.999)]
[2025-10-28 20:49:36,218] [INFO] [timer.py:264:stop] epoch=0/micro_step=28/global_step=28, RunningAvgSamplesPerSec=16.801279632754014, CurrSamplesPerSec=16.798456015628165, MemAllocated=5.3GB, MaxMemAllocated=5.79GB
[Step 28/100] Loss: 5.2259 | Global Tokens/s: 5871.69 | GPU Mem (GB): 5.28 | Peak Mem: 5.79
[2025-10-28 20:49:36,693] [INFO] [logging.py:107:log_dist] [Rank 0] step=29, skipped=0, lr=[2e-05], mom=[(0.9, 0.999)]
[2025-10-28 20:49:36,699] [INFO] [timer.py:264:stop] epoch=0/micro_step=29/global_step=29, RunningAvgSamplesPerSec=16.799144794767376, CurrSamplesPerSec=16.743793760960074, MemAllocated=5.3GB, MaxMemAllocated=5.79GB
[Step 29/100] Loss: 4.9990 | Global Tokens/s: 5852.69 | GPU Mem (GB): 5.28 | Peak Mem: 5.79
[2025-10-28 20:49:37,174] [INFO] [logging.py:107:log_dist] [Rank 0] step=30, skipped=0, lr=[2e-05], mom=[(0.9, 0.999)]
[2025-10-28 20:49:37,180] [INFO] [timer.py:264:stop] epoch=0/micro_step=30/global_step=30, RunningAvgSamplesPerSec=16.79705211876282, CurrSamplesPerSec=16.740711252719866, MemAllocated=5.3GB, MaxMemAllocated=5.79GB
[Step 30/100] Loss: 5.1128 | Global Tokens/s: 5851.50 | GPU Mem (GB): 5.28 | Peak Mem: 5.79
[2025-10-28 20:49:37,656] [INFO] [logging.py:107:log_dist] [Rank 0] step=31, skipped=0, lr=[2e-05], mom=[(0.9, 0.999)]
[2025-10-28 20:49:37,661] [INFO] [timer.py:264:stop] epoch=0/micro_step=31/global_step=31, RunningAvgSamplesPerSec=16.79480334432283, CurrSamplesPerSec=16.732046215688996, MemAllocated=5.3GB, MaxMemAllocated=5.79GB
[Step 31/100] Loss: 5.2009 | Global Tokens/s: 5848.81 | GPU Mem (GB): 5.28 | Peak Mem: 5.79
[2025-10-28 20:49:38,135] [INFO] [logging.py:107:log_dist] [Rank 0] step=32, skipped=0, lr=[2e-05], mom=[(0.9, 0.999)]
[2025-10-28 20:49:38,141] [INFO] [timer.py:264:stop] epoch=0/micro_step=32/global_step=32, RunningAvgSamplesPerSec=16.79448997266138, CurrSamplesPerSec=16.785372060088736, MemAllocated=5.3GB, MaxMemAllocated=5.79GB
[Step 32/100] Loss: 5.2617 | Global Tokens/s: 5867.24 | GPU Mem (GB): 5.28 | Peak Mem: 5.79
[2025-10-28 20:49:38,615] [INFO] [logging.py:107:log_dist] [Rank 0] step=33, skipped=0, lr=[2e-05], mom=[(0.9, 0.999)]
[2025-10-28 20:49:38,620] [INFO] [timer.py:264:stop] epoch=0/micro_step=33/global_step=33, RunningAvgSamplesPerSec=16.79440914091923, CurrSamplesPerSec=16.79194930414293, MemAllocated=5.3GB, MaxMemAllocated=5.79GB
[Step 33/100] Loss: 5.1412 | Global Tokens/s: 5869.61 | GPU Mem (GB): 5.28 | Peak Mem: 5.79
[2025-10-28 20:49:39,093] [INFO] [logging.py:107:log_dist] [Rank 0] step=34, skipped=0, lr=[2e-05], mom=[(0.9, 0.999)]
[2025-10-28 20:49:39,099] [INFO] [timer.py:264:stop] epoch=0/micro_step=34/global_step=34, RunningAvgSamplesPerSec=16.794942799704106, CurrSamplesPerSec=16.81146773223672, MemAllocated=5.3GB, MaxMemAllocated=5.79GB
[Step 34/100] Loss: 5.3723 | Global Tokens/s: 5876.46 | GPU Mem (GB): 5.28 | Peak Mem: 5.79
[2025-10-28 20:49:39,573] [INFO] [logging.py:107:log_dist] [Rank 0] step=35, skipped=0, lr=[2e-05], mom=[(0.9, 0.999)]
[2025-10-28 20:49:39,578] [INFO] [timer.py:264:stop] epoch=0/micro_step=35/global_step=35, RunningAvgSamplesPerSec=16.795380713192248, CurrSamplesPerSec=16.809370693071866, MemAllocated=5.3GB, MaxMemAllocated=5.79GB
[Step 35/100] Loss: 5.5311 | Global Tokens/s: 5875.91 | GPU Mem (GB): 5.28 | Peak Mem: 5.79
[2025-10-28 20:49:40,052] [INFO] [logging.py:107:log_dist] [Rank 0] step=36, skipped=0, lr=[2e-05], mom=[(0.9, 0.999)]
[2025-10-28 20:49:40,057] [INFO] [timer.py:264:stop] epoch=0/micro_step=36/global_step=36, RunningAvgSamplesPerSec=16.7953201201395, CurrSamplesPerSec=16.793285542763147, MemAllocated=5.3GB, MaxMemAllocated=5.79GB
[Step 36/100] Loss: 5.0105 | Global Tokens/s: 5870.04 | GPU Mem (GB): 5.28 | Peak Mem: 5.79
[2025-10-28 20:49:40,533] [INFO] [logging.py:107:log_dist] [Rank 0] step=37, skipped=0, lr=[2e-05], mom=[(0.9, 0.999)]
[2025-10-28 20:49:40,538] [INFO] [timer.py:264:stop] epoch=0/micro_step=37/global_step=37, RunningAvgSamplesPerSec=16.79393580257167, CurrSamplesPerSec=16.74696934635891, MemAllocated=5.3GB, MaxMemAllocated=5.79GB
[Step 37/100] Loss: 5.0342 | Global Tokens/s: 5853.95 | GPU Mem (GB): 5.28 | Peak Mem: 5.79
[2025-10-28 20:49:41,013] [INFO] [logging.py:107:log_dist] [Rank 0] step=38, skipped=0, lr=[2e-05], mom=[(0.9, 0.999)]
[2025-10-28 20:49:41,018] [INFO] [timer.py:264:stop] epoch=0/micro_step=38/global_step=38, RunningAvgSamplesPerSec=16.793346475771823, CurrSamplesPerSec=16.77271089762158, MemAllocated=5.3GB, MaxMemAllocated=5.79GB
[Step 38/100] Loss: 5.0274 | Global Tokens/s: 5862.93 | GPU Mem (GB): 5.28 | Peak Mem: 5.79
[2025-10-28 20:49:41,493] [INFO] [logging.py:107:log_dist] [Rank 0] step=39, skipped=0, lr=[2e-05], mom=[(0.9, 0.999)]
[2025-10-28 20:49:41,499] [INFO] [timer.py:264:stop] epoch=0/micro_step=39/global_step=39, RunningAvgSamplesPerSec=16.792424717526938, CurrSamplesPerSec=16.75927356944696, MemAllocated=5.3GB, MaxMemAllocated=5.79GB
[Step 39/100] Loss: 5.0363 | Global Tokens/s: 5858.04 | GPU Mem (GB): 5.28 | Peak Mem: 5.79
[2025-10-28 20:49:41,972] [INFO] [logging.py:107:log_dist] [Rank 0] step=40, skipped=0, lr=[2e-05], mom=[(0.9, 0.999)]
[2025-10-28 20:49:41,977] [INFO] [timer.py:264:stop] epoch=0/micro_step=40/global_step=40, RunningAvgSamplesPerSec=16.793215072770515, CurrSamplesPerSec=16.822475235283417, MemAllocated=5.3GB, MaxMemAllocated=5.79GB
[Step 40/100] Loss: 4.9699 | Global Tokens/s: 5880.10 | GPU Mem (GB): 5.28 | Peak Mem: 5.79
[2025-10-28 20:49:42,451] [INFO] [logging.py:107:log_dist] [Rank 0] step=41, skipped=0, lr=[2e-05], mom=[(0.9, 0.999)]
[2025-10-28 20:49:42,456] [INFO] [timer.py:264:stop] epoch=0/micro_step=41/global_step=41, RunningAvgSamplesPerSec=16.793625956193964, CurrSamplesPerSec=16.80921912015552, MemAllocated=5.3GB, MaxMemAllocated=5.79GB
[Step 41/100] Loss: 4.8399 | Global Tokens/s: 5875.26 | GPU Mem (GB): 5.28 | Peak Mem: 5.79
[2025-10-28 20:49:42,931] [INFO] [logging.py:107:log_dist] [Rank 0] step=42, skipped=0, lr=[2e-05], mom=[(0.9, 0.999)]
[2025-10-28 20:49:42,936] [INFO] [timer.py:264:stop] epoch=0/micro_step=42/global_step=42, RunningAvgSamplesPerSec=16.793045754667563, CurrSamplesPerSec=16.770413967856776, MemAllocated=5.3GB, MaxMemAllocated=5.79GB
[Step 42/100] Loss: 5.2813 | Global Tokens/s: 5862.02 | GPU Mem (GB): 5.28 | Peak Mem: 5.79
[2025-10-28 20:49:43,412] [INFO] [logging.py:107:log_dist] [Rank 0] step=43, skipped=0, lr=[2e-05], mom=[(0.9, 0.999)]
[2025-10-28 20:49:43,417] [INFO] [timer.py:264:stop] epoch=0/micro_step=43/global_step=43, RunningAvgSamplesPerSec=16.791831651224914, CurrSamplesPerSec=16.743376010430456, MemAllocated=5.3GB, MaxMemAllocated=5.79GB
[Step 43/100] Loss: 5.3166 | Global Tokens/s: 5852.66 | GPU Mem (GB): 5.28 | Peak Mem: 5.79
[2025-10-28 20:49:43,894] [INFO] [logging.py:107:log_dist] [Rank 0] step=44, skipped=0, lr=[2e-05], mom=[(0.9, 0.999)]
[2025-10-28 20:49:43,899] [INFO] [timer.py:264:stop] epoch=0/micro_step=44/global_step=44, RunningAvgSamplesPerSec=16.78962973254523, CurrSamplesPerSec=16.699810754731804, MemAllocated=5.3GB, MaxMemAllocated=5.79GB
[Step 44/100] Loss: 5.2602 | Global Tokens/s: 5837.39 | GPU Mem (GB): 5.28 | Peak Mem: 5.79
[2025-10-28 20:49:44,376] [INFO] [logging.py:107:log_dist] [Rank 0] step=45, skipped=0, lr=[2e-05], mom=[(0.9, 0.999)]
[2025-10-28 20:49:44,381] [INFO] [timer.py:264:stop] epoch=0/micro_step=45/global_step=45, RunningAvgSamplesPerSec=16.787773557500977, CurrSamplesPerSec=16.710148196787877, MemAllocated=5.3GB, MaxMemAllocated=5.79GB
[Step 45/100] Loss: 4.9849 | Global Tokens/s: 5841.09 | GPU Mem (GB): 5.28 | Peak Mem: 5.79
[2025-10-28 20:49:44,856] [INFO] [logging.py:107:log_dist] [Rank 0] step=46, skipped=0, lr=[2e-05], mom=[(0.9, 0.999)]
[2025-10-28 20:49:44,862] [INFO] [timer.py:264:stop] epoch=0/micro_step=46/global_step=46, RunningAvgSamplesPerSec=16.787085470920555, CurrSamplesPerSec=16.757515912019237, MemAllocated=5.3GB, MaxMemAllocated=5.79GB
[Step 46/100] Loss: 5.0799 | Global Tokens/s: 5857.39 | GPU Mem (GB): 5.28 | Peak Mem: 5.79
[2025-10-28 20:49:45,337] [INFO] [logging.py:107:log_dist] [Rank 0] step=47, skipped=0, lr=[2e-05], mom=[(0.9, 0.999)]
[2025-10-28 20:49:45,342] [INFO] [timer.py:264:stop] epoch=0/micro_step=47/global_step=47, RunningAvgSamplesPerSec=16.786599149371195, CurrSamplesPerSec=16.765193727325407, MemAllocated=5.3GB, MaxMemAllocated=5.79GB
[Step 47/100] Loss: 5.1549 | Global Tokens/s: 5860.26 | GPU Mem (GB): 5.28 | Peak Mem: 5.79
[2025-10-28 20:49:45,817] [INFO] [logging.py:107:log_dist] [Rank 0] step=48, skipped=0, lr=[2e-05], mom=[(0.9, 0.999)]
[2025-10-28 20:49:45,822] [INFO] [timer.py:264:stop] epoch=0/micro_step=48/global_step=48, RunningAvgSamplesPerSec=16.786302681085008, CurrSamplesPerSec=16.772937271471374, MemAllocated=5.3GB, MaxMemAllocated=5.79GB
[Step 48/100] Loss: 5.4680 | Global Tokens/s: 5863.04 | GPU Mem (GB): 5.28 | Peak Mem: 5.79
[2025-10-28 20:49:46,296] [INFO] [logging.py:107:log_dist] [Rank 0] step=49, skipped=0, lr=[2e-05], mom=[(0.9, 0.999)]
[2025-10-28 20:49:46,301] [INFO] [timer.py:264:stop] epoch=0/micro_step=49/global_step=49, RunningAvgSamplesPerSec=16.786461768847023, CurrSamplesPerSec=16.793747813175884, MemAllocated=5.3GB, MaxMemAllocated=5.79GB
[Step 49/100] Loss: 5.1333 | Global Tokens/s: 5870.15 | GPU Mem (GB): 5.28 | Peak Mem: 5.79
[2025-10-28 20:49:46,777] [INFO] [logging.py:107:log_dist] [Rank 0] step=50, skipped=0, lr=[2e-05], mom=[(0.9, 0.999)]
[2025-10-28 20:49:46,782] [INFO] [timer.py:264:stop] epoch=0/micro_step=50/global_step=50, RunningAvgSamplesPerSec=16.785480051345278, CurrSamplesPerSec=16.73943347238339, MemAllocated=5.3GB, MaxMemAllocated=5.79GB
[Step 50/100] Loss: 4.8510 | Global Tokens/s: 5851.27 | GPU Mem (GB): 5.28 | Peak Mem: 5.79
[2025-10-28 20:49:47,257] [INFO] [logging.py:107:log_dist] [Rank 0] step=51, skipped=0, lr=[2e-05], mom=[(0.9, 0.999)]
[2025-10-28 20:49:47,262] [INFO] [timer.py:264:stop] epoch=0/micro_step=51/global_step=51, RunningAvgSamplesPerSec=16.78555945073433, CurrSamplesPerSec=16.789336269669104, MemAllocated=5.3GB, MaxMemAllocated=5.79GB
[Step 51/100] Loss: 5.2736 | Global Tokens/s: 5868.85 | GPU Mem (GB): 5.28 | Peak Mem: 5.79
[2025-10-28 20:49:47,737] [INFO] [logging.py:107:log_dist] [Rank 0] step=52, skipped=0, lr=[2e-05], mom=[(0.9, 0.999)]
[2025-10-28 20:49:47,743] [INFO] [timer.py:264:stop] epoch=0/micro_step=52/global_step=52, RunningAvgSamplesPerSec=16.784732706848107, CurrSamplesPerSec=16.74428673339783, MemAllocated=5.3GB, MaxMemAllocated=5.79GB
[Step 52/100] Loss: 5.1034 | Global Tokens/s: 5853.03 | GPU Mem (GB): 5.28 | Peak Mem: 5.79
[2025-10-28 20:49:48,218] [INFO] [logging.py:107:log_dist] [Rank 0] step=53, skipped=0, lr=[2e-05], mom=[(0.9, 0.999)]
[2025-10-28 20:49:48,223] [INFO] [timer.py:264:stop] epoch=0/micro_step=53/global_step=53, RunningAvgSamplesPerSec=16.7840635688368, CurrSamplesPerSec=16.75063948310193, MemAllocated=5.3GB, MaxMemAllocated=5.79GB
[Step 53/100] Loss: 5.2592 | Global Tokens/s: 5854.79 | GPU Mem (GB): 5.28 | Peak Mem: 5.79
[2025-10-28 20:49:48,699] [INFO] [logging.py:107:log_dist] [Rank 0] step=54, skipped=0, lr=[2e-05], mom=[(0.9, 0.999)]
[2025-10-28 20:49:48,704] [INFO] [timer.py:264:stop] epoch=0/micro_step=54/global_step=54, RunningAvgSamplesPerSec=16.78337275436492, CurrSamplesPerSec=16.748181400423046, MemAllocated=5.3GB, MaxMemAllocated=5.79GB
[Step 54/100] Loss: 5.0408 | Global Tokens/s: 5853.94 | GPU Mem (GB): 5.28 | Peak Mem: 5.79
[2025-10-28 20:49:49,179] [INFO] [logging.py:107:log_dist] [Rank 0] step=55, skipped=0, lr=[2e-05], mom=[(0.9, 0.999)]
[2025-10-28 20:49:49,185] [INFO] [timer.py:264:stop] epoch=0/micro_step=55/global_step=55, RunningAvgSamplesPerSec=16.782852346798997, CurrSamplesPerSec=16.755800459153676, MemAllocated=5.3GB, MaxMemAllocated=5.79GB
[Step 55/100] Loss: 5.0182 | Global Tokens/s: 5856.34 | GPU Mem (GB): 5.28 | Peak Mem: 5.79
[2025-10-28 20:49:49,659] [INFO] [logging.py:107:log_dist] [Rank 0] step=56, skipped=0, lr=[2e-05], mom=[(0.9, 0.999)]
[2025-10-28 20:49:49,665] [INFO] [timer.py:264:stop] epoch=0/micro_step=56/global_step=56, RunningAvgSamplesPerSec=16.782797834242647, CurrSamplesPerSec=16.779873979827485, MemAllocated=5.3GB, MaxMemAllocated=5.79GB
[Step 56/100] Loss: 4.7352 | Global Tokens/s: 5865.49 | GPU Mem (GB): 5.28 | Peak Mem: 5.79
[2025-10-28 20:49:50,140] [INFO] [logging.py:107:log_dist] [Rank 0] step=57, skipped=0, lr=[2e-05], mom=[(0.9, 0.999)]
[2025-10-28 20:49:50,145] [INFO] [timer.py:264:stop] epoch=0/micro_step=57/global_step=57, RunningAvgSamplesPerSec=16.782241213282575, CurrSamplesPerSec=16.7522033329139, MemAllocated=5.3GB, MaxMemAllocated=5.79GB
[Step 57/100] Loss: 5.2569 | Global Tokens/s: 5855.78 | GPU Mem (GB): 5.28 | Peak Mem: 5.79
[2025-10-28 20:49:50,621] [INFO] [logging.py:107:log_dist] [Rank 0] step=58, skipped=0, lr=[2e-05], mom=[(0.9, 0.999)]
[2025-10-28 20:49:50,627] [INFO] [timer.py:264:stop] epoch=0/micro_step=58/global_step=58, RunningAvgSamplesPerSec=16.781347507823043, CurrSamplesPerSec=16.732304868156984, MemAllocated=5.3GB, MaxMemAllocated=5.79GB
[Step 58/100] Loss: 5.0744 | Global Tokens/s: 5848.83 | GPU Mem (GB): 5.28 | Peak Mem: 5.79
[2025-10-28 20:49:51,103] [INFO] [logging.py:107:log_dist] [Rank 0] step=59, skipped=0, lr=[2e-05], mom=[(0.9, 0.999)]
[2025-10-28 20:49:51,108] [INFO] [timer.py:264:stop] epoch=0/micro_step=59/global_step=59, RunningAvgSamplesPerSec=16.780081566911797, CurrSamplesPerSec=16.70945752637334, MemAllocated=5.3GB, MaxMemAllocated=5.79GB
[Step 59/100] Loss: 5.1346 | Global Tokens/s: 5840.79 | GPU Mem (GB): 5.28 | Peak Mem: 5.79
[2025-10-28 20:49:51,585] [INFO] [logging.py:107:log_dist] [Rank 0] step=60, skipped=0, lr=[2e-05], mom=[(0.9, 0.999)]
[2025-10-28 20:49:51,590] [INFO] [timer.py:264:stop] epoch=0/micro_step=60/global_step=60, RunningAvgSamplesPerSec=16.778994573424782, CurrSamplesPerSec=16.717232944084014, MemAllocated=5.3GB, MaxMemAllocated=5.79GB
[Step 60/100] Loss: 4.9282 | Global Tokens/s: 5843.61 | GPU Mem (GB): 5.28 | Peak Mem: 5.79
[2025-10-28 20:49:52,066] [INFO] [logging.py:107:log_dist] [Rank 0] step=61, skipped=0, lr=[2e-05], mom=[(0.9, 0.999)]
[2025-10-28 20:49:52,071] [INFO] [timer.py:264:stop] epoch=0/micro_step=61/global_step=61, RunningAvgSamplesPerSec=16.778079075762626, CurrSamplesPerSec=16.72511563990327, MemAllocated=5.3GB, MaxMemAllocated=5.79GB
[Step 61/100] Loss: 4.8975 | Global Tokens/s: 5846.29 | GPU Mem (GB): 5.28 | Peak Mem: 5.79
[2025-10-28 20:49:52,546] [INFO] [logging.py:107:log_dist] [Rank 0] step=62, skipped=0, lr=[2e-05], mom=[(0.9, 0.999)]
[2025-10-28 20:49:52,552] [INFO] [timer.py:264:stop] epoch=0/micro_step=62/global_step=62, RunningAvgSamplesPerSec=16.777829928760145, CurrSamplesPerSec=16.76310821586686, MemAllocated=5.3GB, MaxMemAllocated=5.79GB
[Step 62/100] Loss: 5.1669 | Global Tokens/s: 5859.43 | GPU Mem (GB): 5.28 | Peak Mem: 5.79
[2025-10-28 20:49:53,025] [INFO] [logging.py:107:log_dist] [Rank 0] step=63, skipped=0, lr=[2e-05], mom=[(0.9, 0.999)]
[2025-10-28 20:49:53,031] [INFO] [timer.py:264:stop] epoch=0/micro_step=63/global_step=63, RunningAvgSamplesPerSec=16.778453204631383, CurrSamplesPerSec=16.81589934273972, MemAllocated=5.3GB, MaxMemAllocated=5.79GB
[Step 63/100] Loss: 4.8046 | Global Tokens/s: 5877.92 | GPU Mem (GB): 5.28 | Peak Mem: 5.79
[2025-10-28 20:49:53,504] [INFO] [logging.py:107:log_dist] [Rank 0] step=64, skipped=0, lr=[2e-05], mom=[(0.9, 0.999)]
[2025-10-28 20:49:53,510] [INFO] [timer.py:264:stop] epoch=0/micro_step=64/global_step=64, RunningAvgSamplesPerSec=16.778785222356642, CurrSamplesPerSec=16.79902790567636, MemAllocated=5.3GB, MaxMemAllocated=5.79GB
[Step 64/100] Loss: 5.4337 | Global Tokens/s: 5871.89 | GPU Mem (GB): 5.28 | Peak Mem: 5.79
[2025-10-28 20:49:53,984] [INFO] [logging.py:107:log_dist] [Rank 0] step=65, skipped=0, lr=[2e-05], mom=[(0.9, 0.999)]
[2025-10-28 20:49:53,990] [INFO] [timer.py:264:stop] epoch=0/micro_step=65/global_step=65, RunningAvgSamplesPerSec=16.7786853334442, CurrSamplesPerSec=16.772459378288282, MemAllocated=5.3GB, MaxMemAllocated=5.79GB
[Step 65/100] Loss: 5.1483 | Global Tokens/s: 5862.79 | GPU Mem (GB): 5.28 | Peak Mem: 5.79
[2025-10-28 20:49:54,465] [INFO] [logging.py:107:log_dist] [Rank 0] step=66, skipped=0, lr=[2e-05], mom=[(0.9, 0.999)]
[2025-10-28 20:49:54,470] [INFO] [timer.py:264:stop] epoch=0/micro_step=66/global_step=66, RunningAvgSamplesPerSec=16.778396124221143, CurrSamplesPerSec=16.760160907992965, MemAllocated=5.3GB, MaxMemAllocated=5.79GB
[Step 66/100] Loss: 5.2754 | Global Tokens/s: 5858.48 | GPU Mem (GB): 5.28 | Peak Mem: 5.79
[2025-10-28 20:49:54,945] [INFO] [logging.py:107:log_dist] [Rank 0] step=67, skipped=0, lr=[2e-05], mom=[(0.9, 0.999)]
[2025-10-28 20:49:54,950] [INFO] [timer.py:264:stop] epoch=0/micro_step=67/global_step=67, RunningAvgSamplesPerSec=16.778274967277742, CurrSamplesPerSec=16.770489404462225, MemAllocated=5.3GB, MaxMemAllocated=5.79GB
[Step 67/100] Loss: 4.7900 | Global Tokens/s: 5862.11 | GPU Mem (GB): 5.28 | Peak Mem: 5.79
[2025-10-28 20:49:55,425] [INFO] [logging.py:107:log_dist] [Rank 0] step=68, skipped=0, lr=[2e-05], mom=[(0.9, 0.999)]
[2025-10-28 20:49:55,430] [INFO] [timer.py:264:stop] epoch=0/micro_step=68/global_step=68, RunningAvgSamplesPerSec=16.778390233098282, CurrSamplesPerSec=16.785850689400732, MemAllocated=5.3GB, MaxMemAllocated=5.79GB
[Step 68/100] Loss: 4.8694 | Global Tokens/s: 5867.53 | GPU Mem (GB): 5.28 | Peak Mem: 5.79
[2025-10-28 20:49:55,903] [INFO] [logging.py:107:log_dist] [Rank 0] step=69, skipped=0, lr=[2e-05], mom=[(0.9, 0.999)]
[2025-10-28 20:49:55,909] [INFO] [timer.py:264:stop] epoch=0/micro_step=69/global_step=69, RunningAvgSamplesPerSec=16.77895938396644, CurrSamplesPerSec=16.816573556645576, MemAllocated=5.3GB, MaxMemAllocated=5.79GB
[Step 69/100] Loss: 5.2859 | Global Tokens/s: 5878.36 | GPU Mem (GB): 5.28 | Peak Mem: 5.79
[2025-10-28 20:49:56,383] [INFO] [logging.py:107:log_dist] [Rank 0] step=70, skipped=0, lr=[2e-05], mom=[(0.9, 0.999)]
[2025-10-28 20:49:56,388] [INFO] [timer.py:264:stop] epoch=0/micro_step=70/global_step=70, RunningAvgSamplesPerSec=16.77931662238833, CurrSamplesPerSec=16.80325100496275, MemAllocated=5.3GB, MaxMemAllocated=5.79GB
[Step 70/100] Loss: 5.4392 | Global Tokens/s: 5873.56 | GPU Mem (GB): 5.28 | Peak Mem: 5.79
[2025-10-28 20:49:56,862] [INFO] [logging.py:107:log_dist] [Rank 0] step=71, skipped=0, lr=[2e-05], mom=[(0.9, 0.999)]
[2025-10-28 20:49:56,868] [INFO] [timer.py:264:stop] epoch=0/micro_step=71/global_step=71, RunningAvgSamplesPerSec=16.779441586223147, CurrSamplesPerSec=16.787908266586953, MemAllocated=5.3GB, MaxMemAllocated=5.79GB
[Step 71/100] Loss: 4.9338 | Global Tokens/s: 5868.01 | GPU Mem (GB): 5.28 | Peak Mem: 5.79
[2025-10-28 20:49:57,343] [INFO] [logging.py:107:log_dist] [Rank 0] step=72, skipped=0, lr=[2e-05], mom=[(0.9, 0.999)]
[2025-10-28 20:49:57,348] [INFO] [timer.py:264:stop] epoch=0/micro_step=72/global_step=72, RunningAvgSamplesPerSec=16.779038922728677, CurrSamplesPerSec=16.75126666052379, MemAllocated=5.3GB, MaxMemAllocated=5.79GB
[Step 72/100] Loss: 5.2399 | Global Tokens/s: 5855.38 | GPU Mem (GB): 5.28 | Peak Mem: 5.79
[2025-10-28 20:49:57,823] [INFO] [logging.py:107:log_dist] [Rank 0] step=73, skipped=0, lr=[2e-05], mom=[(0.9, 0.999)]
[2025-10-28 20:49:57,829] [INFO] [timer.py:264:stop] epoch=0/micro_step=73/global_step=73, RunningAvgSamplesPerSec=16.778755864411444, CurrSamplesPerSec=16.758930378793135, MemAllocated=5.3GB, MaxMemAllocated=5.79GB
[Step 73/100] Loss: 5.0639 | Global Tokens/s: 5857.64 | GPU Mem (GB): 5.28 | Peak Mem: 5.79
[2025-10-28 20:49:58,305] [INFO] [logging.py:107:log_dist] [Rank 0] step=74, skipped=0, lr=[2e-05], mom=[(0.9, 0.999)]
[2025-10-28 20:49:58,310] [INFO] [timer.py:264:stop] epoch=0/micro_step=74/global_step=74, RunningAvgSamplesPerSec=16.77793570353362, CurrSamplesPerSec=16.719873569225186, MemAllocated=5.3GB, MaxMemAllocated=5.79GB
[Step 74/100] Loss: 5.2709 | Global Tokens/s: 5844.53 | GPU Mem (GB): 5.28 | Peak Mem: 5.79
[2025-10-28 20:49:58,786] [INFO] [logging.py:107:log_dist] [Rank 0] step=75, skipped=0, lr=[2e-05], mom=[(0.9, 0.999)]
[2025-10-28 20:49:58,792] [INFO] [timer.py:264:stop] epoch=0/micro_step=75/global_step=75, RunningAvgSamplesPerSec=16.77717727459766, CurrSamplesPerSec=16.72271504701656, MemAllocated=5.3GB, MaxMemAllocated=5.79GB
[Step 75/100] Loss: 5.1584 | Global Tokens/s: 5845.11 | GPU Mem (GB): 5.28 | Peak Mem: 5.79
[2025-10-28 20:49:59,265] [INFO] [logging.py:107:log_dist] [Rank 0] step=76, skipped=0, lr=[2e-05], mom=[(0.9, 0.999)]
[2025-10-28 20:49:59,270] [INFO] [timer.py:264:stop] epoch=0/micro_step=76/global_step=76, RunningAvgSamplesPerSec=16.777822495610483, CurrSamplesPerSec=16.825022667324603, MemAllocated=5.3GB, MaxMemAllocated=5.79GB
[Step 76/100] Loss: 5.4352 | Global Tokens/s: 5880.88 | GPU Mem (GB): 5.28 | Peak Mem: 5.79
[2025-10-28 20:49:59,744] [INFO] [logging.py:107:log_dist] [Rank 0] step=77, skipped=0, lr=[2e-05], mom=[(0.9, 0.999)]
[2025-10-28 20:49:59,750] [INFO] [timer.py:264:stop] epoch=0/micro_step=77/global_step=77, RunningAvgSamplesPerSec=16.778014633496554, CurrSamplesPerSec=16.792209811965318, MemAllocated=5.3GB, MaxMemAllocated=5.79GB
[Step 77/100] Loss: 5.2888 | Global Tokens/s: 5869.70 | GPU Mem (GB): 5.28 | Peak Mem: 5.79
[2025-10-28 20:50:00,223] [INFO] [logging.py:107:log_dist] [Rank 0] step=78, skipped=0, lr=[2e-05], mom=[(0.9, 0.999)]
[2025-10-28 20:50:00,229] [INFO] [timer.py:264:stop] epoch=0/micro_step=78/global_step=78, RunningAvgSamplesPerSec=16.778503198196013, CurrSamplesPerSec=16.815191476319786, MemAllocated=5.3GB, MaxMemAllocated=5.79GB
[Step 78/100] Loss: 4.9498 | Global Tokens/s: 5877.11 | GPU Mem (GB): 5.28 | Peak Mem: 5.79
[2025-10-28 20:50:00,705] [INFO] [logging.py:107:log_dist] [Rank 0] step=79, skipped=0, lr=[2e-05], mom=[(0.9, 0.999)]
[2025-10-28 20:50:00,710] [INFO] [timer.py:264:stop] epoch=0/micro_step=79/global_step=79, RunningAvgSamplesPerSec=16.7776297755707, CurrSamplesPerSec=16.711479770768, MemAllocated=5.3GB, MaxMemAllocated=5.79GB
[Step 79/100] Loss: 4.9896 | Global Tokens/s: 5841.33 | GPU Mem (GB): 5.28 | Peak Mem: 5.79
[2025-10-28 20:50:01,185] [INFO] [logging.py:107:log_dist] [Rank 0] step=80, skipped=0, lr=[2e-05], mom=[(0.9, 0.999)]
[2025-10-28 20:50:01,191] [INFO] [timer.py:264:stop] epoch=0/micro_step=80/global_step=80, RunningAvgSamplesPerSec=16.777436150075633, CurrSamplesPerSec=16.762505273111934, MemAllocated=5.3GB, MaxMemAllocated=5.79GB
[Step 80/100] Loss: 4.9510 | Global Tokens/s: 5859.40 | GPU Mem (GB): 5.28 | Peak Mem: 5.79
[2025-10-28 20:50:01,667] [INFO] [logging.py:107:log_dist] [Rank 0] step=81, skipped=0, lr=[2e-05], mom=[(0.9, 0.999)]
[2025-10-28 20:50:01,672] [INFO] [timer.py:264:stop] epoch=0/micro_step=81/global_step=81, RunningAvgSamplesPerSec=16.776823337387963, CurrSamplesPerSec=16.72912650060591, MemAllocated=5.3GB, MaxMemAllocated=5.79GB
[Step 81/100] Loss: 5.2063 | Global Tokens/s: 5847.67 | GPU Mem (GB): 5.28 | Peak Mem: 5.79
[2025-10-28 20:50:02,149] [INFO] [logging.py:107:log_dist] [Rank 0] step=82, skipped=0, lr=[2e-05], mom=[(0.9, 0.999)]
[2025-10-28 20:50:02,154] [INFO] [timer.py:264:stop] epoch=0/micro_step=82/global_step=82, RunningAvgSamplesPerSec=16.775845203748787, CurrSamplesPerSec=16.698896552836, MemAllocated=5.3GB, MaxMemAllocated=5.79GB
[Step 82/100] Loss: 4.9518 | Global Tokens/s: 5836.76 | GPU Mem (GB): 5.28 | Peak Mem: 5.79
[2025-10-28 20:50:02,630] [INFO] [logging.py:107:log_dist] [Rank 0] step=83, skipped=0, lr=[2e-05], mom=[(0.9, 0.999)]
[2025-10-28 20:50:02,636] [INFO] [timer.py:264:stop] epoch=0/micro_step=83/global_step=83, RunningAvgSamplesPerSec=16.775144166145207, CurrSamplesPerSec=16.71921541741178, MemAllocated=5.3GB, MaxMemAllocated=5.79GB
[Step 83/100] Loss: 5.1427 | Global Tokens/s: 5844.00 | GPU Mem (GB): 5.28 | Peak Mem: 5.79
[2025-10-28 20:50:03,109] [INFO] [logging.py:107:log_dist] [Rank 0] step=84, skipped=0, lr=[2e-05], mom=[(0.9, 0.999)]
[2025-10-28 20:50:03,115] [INFO] [timer.py:264:stop] epoch=0/micro_step=84/global_step=84, RunningAvgSamplesPerSec=16.77561055361196, CurrSamplesPerSec=16.813438920695422, MemAllocated=5.3GB, MaxMemAllocated=5.79GB
[Step 84/100] Loss: 4.8197 | Global Tokens/s: 5877.14 | GPU Mem (GB): 5.28 | Peak Mem: 5.79
[2025-10-28 20:50:03,589] [INFO] [logging.py:107:log_dist] [Rank 0] step=85, skipped=0, lr=[2e-05], mom=[(0.9, 0.999)]
[2025-10-28 20:50:03,594] [INFO] [timer.py:264:stop] epoch=0/micro_step=85/global_step=85, RunningAvgSamplesPerSec=16.775848263069925, CurrSamplesPerSec=16.79532812968815, MemAllocated=5.3GB, MaxMemAllocated=5.79GB
[Step 85/100] Loss: 5.0517 | Global Tokens/s: 5870.61 | GPU Mem (GB): 5.28 | Peak Mem: 5.79
[2025-10-28 20:50:04,069] [INFO] [logging.py:107:log_dist] [Rank 0] step=86, skipped=0, lr=[2e-05], mom=[(0.9, 0.999)]
[2025-10-28 20:50:04,074] [INFO] [timer.py:264:stop] epoch=0/micro_step=86/global_step=86, RunningAvgSamplesPerSec=16.775813422170668, CurrSamplesPerSec=16.77288696564335, MemAllocated=5.3GB, MaxMemAllocated=5.79GB
[Step 86/100] Loss: 5.1183 | Global Tokens/s: 5862.93 | GPU Mem (GB): 5.28 | Peak Mem: 5.79
[2025-10-28 20:50:04,548] [INFO] [logging.py:107:log_dist] [Rank 0] step=87, skipped=0, lr=[2e-05], mom=[(0.9, 0.999)]
[2025-10-28 20:50:04,553] [INFO] [timer.py:264:stop] epoch=0/micro_step=87/global_step=87, RunningAvgSamplesPerSec=16.77632527581212, CurrSamplesPerSec=16.819397414677915, MemAllocated=5.3GB, MaxMemAllocated=5.79GB
[Step 87/100] Loss: 5.2328 | Global Tokens/s: 5878.99 | GPU Mem (GB): 5.28 | Peak Mem: 5.79
[2025-10-28 20:50:05,027] [INFO] [logging.py:107:log_dist] [Rank 0] step=88, skipped=0, lr=[2e-05], mom=[(0.9, 0.999)]
[2025-10-28 20:50:05,033] [INFO] [timer.py:264:stop] epoch=0/micro_step=88/global_step=88, RunningAvgSamplesPerSec=16.77644701448685, CurrSamplesPerSec=16.786766039008302, MemAllocated=5.3GB, MaxMemAllocated=5.79GB
[Step 88/100] Loss: 5.1486 | Global Tokens/s: 5867.63 | GPU Mem (GB): 5.28 | Peak Mem: 5.79
[2025-10-28 20:50:05,507] [INFO] [logging.py:107:log_dist] [Rank 0] step=89, skipped=0, lr=[2e-05], mom=[(0.9, 0.999)]
[2025-10-28 20:50:05,513] [INFO] [timer.py:264:stop] epoch=0/micro_step=89/global_step=89, RunningAvgSamplesPerSec=16.776385472503105, CurrSamplesPerSec=16.771059391861225, MemAllocated=5.3GB, MaxMemAllocated=5.79GB
[Step 89/100] Loss: 5.0196 | Global Tokens/s: 5862.40 | GPU Mem (GB): 5.28 | Peak Mem: 5.79
[2025-10-28 20:50:05,988] [INFO] [logging.py:107:log_dist] [Rank 0] step=90, skipped=0, lr=[2e-05], mom=[(0.9, 0.999)]
[2025-10-28 20:50:05,993] [INFO] [timer.py:264:stop] epoch=0/micro_step=90/global_step=90, RunningAvgSamplesPerSec=16.776076370630186, CurrSamplesPerSec=16.74919297293868, MemAllocated=5.3GB, MaxMemAllocated=5.79GB
[Step 90/100] Loss: 5.1874 | Global Tokens/s: 5854.22 | GPU Mem (GB): 5.28 | Peak Mem: 5.79
[2025-10-28 20:50:06,467] [INFO] [logging.py:107:log_dist] [Rank 0] step=91, skipped=0, lr=[2e-05], mom=[(0.9, 0.999)]
[2025-10-28 20:50:06,473] [INFO] [timer.py:264:stop] epoch=0/micro_step=91/global_step=91, RunningAvgSamplesPerSec=16.776271627855557, CurrSamplesPerSec=16.79343682846032, MemAllocated=5.3GB, MaxMemAllocated=5.79GB
[Step 91/100] Loss: 4.9818 | Global Tokens/s: 5870.06 | GPU Mem (GB): 5.28 | Peak Mem: 5.79
[2025-10-28 20:50:06,948] [INFO] [logging.py:107:log_dist] [Rank 0] step=92, skipped=0, lr=[2e-05], mom=[(0.9, 0.999)]
[2025-10-28 20:50:06,953] [INFO] [timer.py:264:stop] epoch=0/micro_step=92/global_step=92, RunningAvgSamplesPerSec=16.776021081298424, CurrSamplesPerSec=16.753717283852257, MemAllocated=5.3GB, MaxMemAllocated=5.79GB
[Step 92/100] Loss: 4.8823 | Global Tokens/s: 5856.18 | GPU Mem (GB): 5.28 | Peak Mem: 5.79
[2025-10-28 20:50:07,429] [INFO] [logging.py:107:log_dist] [Rank 0] step=93, skipped=0, lr=[2e-05], mom=[(0.9, 0.999)]
[2025-10-28 20:50:07,434] [INFO] [timer.py:264:stop] epoch=0/micro_step=93/global_step=93, RunningAvgSamplesPerSec=16.77560968928541, CurrSamplesPerSec=16.738631827446177, MemAllocated=5.3GB, MaxMemAllocated=5.79GB
[Step 93/100] Loss: 5.2548 | Global Tokens/s: 5850.96 | GPU Mem (GB): 5.28 | Peak Mem: 5.79
[2025-10-28 20:50:07,909] [INFO] [logging.py:107:log_dist] [Rank 0] step=94, skipped=0, lr=[2e-05], mom=[(0.9, 0.999)]
[2025-10-28 20:50:07,915] [INFO] [timer.py:264:stop] epoch=0/micro_step=94/global_step=94, RunningAvgSamplesPerSec=16.775539540102915, CurrSamplesPerSec=16.769123268868906, MemAllocated=5.3GB, MaxMemAllocated=5.79GB
[Step 94/100] Loss: 4.9215 | Global Tokens/s: 5861.65 | GPU Mem (GB): 5.28 | Peak Mem: 5.79
[2025-10-28 20:50:08,388] [INFO] [logging.py:107:log_dist] [Rank 0] step=95, skipped=0, lr=[2e-05], mom=[(0.9, 0.999)]
[2025-10-28 20:50:08,394] [INFO] [timer.py:264:stop] epoch=0/micro_step=95/global_step=95, RunningAvgSamplesPerSec=16.7759064871705, CurrSamplesPerSec=16.80969911043503, MemAllocated=5.3GB, MaxMemAllocated=5.79GB
[Step 95/100] Loss: 5.0549 | Global Tokens/s: 5875.89 | GPU Mem (GB): 5.28 | Peak Mem: 5.79
[2025-10-28 20:50:08,867] [INFO] [logging.py:107:log_dist] [Rank 0] step=96, skipped=0, lr=[2e-05], mom=[(0.9, 0.999)]
[2025-10-28 20:50:08,872] [INFO] [timer.py:264:stop] epoch=0/micro_step=96/global_step=96, RunningAvgSamplesPerSec=16.776358264065774, CurrSamplesPerSec=16.81844478344106, MemAllocated=5.3GB, MaxMemAllocated=5.79GB
[Step 96/100] Loss: 5.3572 | Global Tokens/s: 5878.76 | GPU Mem (GB): 5.28 | Peak Mem: 5.79
[2025-10-28 20:50:09,347] [INFO] [logging.py:107:log_dist] [Rank 0] step=97, skipped=0, lr=[2e-05], mom=[(0.9, 0.999)]
[2025-10-28 20:50:09,353] [INFO] [timer.py:264:stop] epoch=0/micro_step=97/global_step=97, RunningAvgSamplesPerSec=16.776173228390384, CurrSamplesPerSec=16.758762973818488, MemAllocated=5.3GB, MaxMemAllocated=5.79GB
[Step 97/100] Loss: 5.0092 | Global Tokens/s: 5858.00 | GPU Mem (GB): 5.28 | Peak Mem: 5.79
[2025-10-28 20:50:09,828] [INFO] [logging.py:107:log_dist] [Rank 0] step=98, skipped=0, lr=[2e-05], mom=[(0.9, 0.999)]
[2025-10-28 20:50:09,833] [INFO] [timer.py:264:stop] epoch=0/micro_step=98/global_step=98, RunningAvgSamplesPerSec=16.77597405367084, CurrSamplesPerSec=16.757038897187943, MemAllocated=5.3GB, MaxMemAllocated=5.79GB
[Step 98/100] Loss: 4.8929 | Global Tokens/s: 5856.54 | GPU Mem (GB): 5.28 | Peak Mem: 5.79
[2025-10-28 20:50:10,309] [INFO] [logging.py:107:log_dist] [Rank 0] step=99, skipped=0, lr=[2e-05], mom=[(0.9, 0.999)]
[2025-10-28 20:50:10,314] [INFO] [timer.py:264:stop] epoch=0/micro_step=99/global_step=99, RunningAvgSamplesPerSec=16.775689931052046, CurrSamplesPerSec=16.748423832289422, MemAllocated=5.3GB, MaxMemAllocated=5.79GB
[Step 99/100] Loss: 4.8612 | Global Tokens/s: 5854.14 | GPU Mem (GB): 5.28 | Peak Mem: 5.79
[2025-10-28 20:50:10,790] [INFO] [logging.py:107:log_dist] [Rank 0] step=100, skipped=0, lr=[2e-05], mom=[(0.9, 0.999)]
[2025-10-28 20:50:10,795] [INFO] [timer.py:264:stop] epoch=0/micro_step=100/global_step=100, RunningAvgSamplesPerSec=16.775249701088608, CurrSamplesPerSec=16.732621936930396, MemAllocated=5.3GB, MaxMemAllocated=5.79GB
[Step 100/100] Loss: 5.1290 | Global Tokens/s: 5848.51 | GPU Mem (GB): 5.28 | Peak Mem: 5.79

Training done in 49.87 seconds.
Avg Global Tokens/s: 5673.65
Peak GPU Mem (GB): 5.79
